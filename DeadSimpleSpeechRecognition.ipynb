{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\damon\\documents\\sxsw18\\deadsimplespeechrecognizer\\env\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Saving vectors of label - 'bass-drum': 100%|██████████████████████████████████████████| 20/20 [00:00<00:00, 226.61it/s]\n",
      "Saving vectors of label - 'cowbell': 100%|████████████████████████████████████████████| 22/22 [00:00<00:00, 259.56it/s]\n",
      "Saving vectors of label - 'cymbal': 100%|█████████████████████████████████████████████| 22/22 [00:00<00:00, 239.80it/s]\n",
      "Saving vectors of label - 'handclap': 100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 249.34it/s]\n",
      "Saving vectors of label - 'hi-hat': 100%|█████████████████████████████████████████████| 22/22 [00:00<00:00, 250.69it/s]\n",
      "Saving vectors of label - 'rimshot': 100%|████████████████████████████████████████████| 24/24 [00:00<00:00, 250.68it/s]\n",
      "Saving vectors of label - 'snare': 100%|██████████████████████████████████████████████| 23/23 [00:00<00:00, 253.47it/s]\n",
      "Saving vectors of label - 'toms': 100%|███████████████████████████████████████████████| 24/24 [00:00<00:00, 245.45it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 11\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# # Feature dimension\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 380\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 8\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]\n",
    "\n",
    "import time\n",
    "\n",
    "def test(directory, model):\n",
    "    labels = os.listdir(directory)\n",
    "    for l in labels:\n",
    "        files = os.listdir(os.path.join(directory, l))\n",
    "        for f in files:\n",
    "            path = os.path.join(directory, l, f)\n",
    "            start = time.time()\n",
    "            print (l, predict(path, model), time.time()-start, \"secs\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The Model Then Training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 109 samples, validate on 73 samples\n",
      "Epoch 1/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 8.2533 - acc: 0.090 - 5s 43ms/step - loss: 7.9339 - acc: 0.1009 - val_loss: 3.3274 - val_acc: 0.0959\n",
      "Epoch 2/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 4.5966 - acc: 0.130 - 0s 221us/step - loss: 4.5194 - acc: 0.1284 - val_loss: 2.0168 - val_acc: 0.2740\n",
      "Epoch 3/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 2.4491 - acc: 0.240 - 0s 239us/step - loss: 2.3569 - acc: 0.2661 - val_loss: 1.9536 - val_acc: 0.3014\n",
      "Epoch 4/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 2.2194 - acc: 0.290 - 0s 230us/step - loss: 2.1554 - acc: 0.2936 - val_loss: 1.4893 - val_acc: 0.5479\n",
      "Epoch 5/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.6519 - acc: 0.450 - 0s 267us/step - loss: 1.6852 - acc: 0.4220 - val_loss: 1.6468 - val_acc: 0.3562\n",
      "Epoch 6/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.8168 - acc: 0.370 - 0s 235us/step - loss: 1.7966 - acc: 0.3945 - val_loss: 1.2787 - val_acc: 0.4658\n",
      "Epoch 7/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.9485 - acc: 0.400 - 0s 230us/step - loss: 1.8909 - acc: 0.4037 - val_loss: 1.2134 - val_acc: 0.5616\n",
      "Epoch 8/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.4492 - acc: 0.540 - 0s 239us/step - loss: 1.4606 - acc: 0.5413 - val_loss: 1.2946 - val_acc: 0.6164\n",
      "Epoch 9/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.4111 - acc: 0.580 - 0s 221us/step - loss: 1.4608 - acc: 0.5505 - val_loss: 1.3757 - val_acc: 0.4384\n",
      "Epoch 10/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.4907 - acc: 0.470 - 0s 239us/step - loss: 1.4053 - acc: 0.5046 - val_loss: 1.1673 - val_acc: 0.6027\n",
      "Epoch 11/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.2582 - acc: 0.570 - 0s 221us/step - loss: 1.2693 - acc: 0.5596 - val_loss: 1.0856 - val_acc: 0.6575\n",
      "Epoch 12/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.0822 - acc: 0.610 - 0s 235us/step - loss: 1.0756 - acc: 0.6147 - val_loss: 0.9826 - val_acc: 0.6712\n",
      "Epoch 13/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.0629 - acc: 0.670 - 0s 239us/step - loss: 1.0482 - acc: 0.6789 - val_loss: 0.8948 - val_acc: 0.7534\n",
      "Epoch 14/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.0915 - acc: 0.620 - 0s 235us/step - loss: 1.0958 - acc: 0.6239 - val_loss: 0.7235 - val_acc: 0.8082\n",
      "Epoch 15/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.9766 - acc: 0.660 - 0s 244us/step - loss: 0.9608 - acc: 0.6697 - val_loss: 0.6576 - val_acc: 0.9178\n",
      "Epoch 16/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.8188 - acc: 0.650 - 0s 258us/step - loss: 0.8532 - acc: 0.6422 - val_loss: 0.6420 - val_acc: 0.8767\n",
      "Epoch 17/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.0672 - acc: 0.640 - 0s 235us/step - loss: 1.0344 - acc: 0.6422 - val_loss: 0.6062 - val_acc: 0.8219\n",
      "Epoch 18/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.9039 - acc: 0.700 - 0s 226us/step - loss: 0.8589 - acc: 0.7248 - val_loss: 0.5669 - val_acc: 0.8493\n",
      "Epoch 19/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.7606 - acc: 0.720 - 0s 253us/step - loss: 0.7219 - acc: 0.7431 - val_loss: 0.4976 - val_acc: 0.8767\n",
      "Epoch 20/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6684 - acc: 0.790 - 0s 212us/step - loss: 0.6364 - acc: 0.7982 - val_loss: 0.4072 - val_acc: 0.9041\n",
      "Epoch 21/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6176 - acc: 0.780 - 0s 211us/step - loss: 0.6280 - acc: 0.7798 - val_loss: 0.5504 - val_acc: 0.8493\n",
      "Epoch 22/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6356 - acc: 0.800 - 0s 221us/step - loss: 0.6342 - acc: 0.7982 - val_loss: 0.4546 - val_acc: 0.8630\n",
      "Epoch 23/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6813 - acc: 0.770 - 0s 226us/step - loss: 0.6369 - acc: 0.7890 - val_loss: 0.4765 - val_acc: 0.8356\n",
      "Epoch 24/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4901 - acc: 0.840 - 0s 262us/step - loss: 0.5462 - acc: 0.8349 - val_loss: 0.3958 - val_acc: 0.9315\n",
      "Epoch 25/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5187 - acc: 0.830 - 0s 230us/step - loss: 0.5439 - acc: 0.8257 - val_loss: 0.4917 - val_acc: 0.8082\n",
      "Epoch 26/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.8589 - acc: 0.710 - 0s 253us/step - loss: 0.8346 - acc: 0.7156 - val_loss: 0.4239 - val_acc: 0.8904\n",
      "Epoch 27/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5496 - acc: 0.790 - 0s 230us/step - loss: 0.5179 - acc: 0.8073 - val_loss: 0.3625 - val_acc: 0.9315\n",
      "Epoch 28/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3716 - acc: 0.860 - 0s 258us/step - loss: 0.3730 - acc: 0.8624 - val_loss: 0.3410 - val_acc: 0.9041\n",
      "Epoch 29/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5990 - acc: 0.780 - 0s 212us/step - loss: 0.5901 - acc: 0.7798 - val_loss: 0.3237 - val_acc: 0.9178\n",
      "Epoch 30/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4627 - acc: 0.830 - 0s 244us/step - loss: 0.4599 - acc: 0.8440 - val_loss: 0.3032 - val_acc: 0.9178\n",
      "Epoch 31/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4651 - acc: 0.860 - 0s 248us/step - loss: 0.4531 - acc: 0.8624 - val_loss: 0.2966 - val_acc: 0.8904\n",
      "Epoch 32/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3938 - acc: 0.870 - 0s 262us/step - loss: 0.4193 - acc: 0.8624 - val_loss: 0.2960 - val_acc: 0.9178\n",
      "Epoch 33/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4006 - acc: 0.840 - 0s 225us/step - loss: 0.3852 - acc: 0.8440 - val_loss: 0.2907 - val_acc: 0.8904\n",
      "Epoch 34/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3763 - acc: 0.860 - 0s 230us/step - loss: 0.3497 - acc: 0.8716 - val_loss: 0.2607 - val_acc: 0.9041\n",
      "Epoch 35/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4059 - acc: 0.890 - 0s 202us/step - loss: 0.3880 - acc: 0.8991 - val_loss: 0.2780 - val_acc: 0.9178\n",
      "Epoch 36/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2990 - acc: 0.920 - 0s 239us/step - loss: 0.3037 - acc: 0.9174 - val_loss: 0.5729 - val_acc: 0.7808\n",
      "Epoch 37/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5006 - acc: 0.800 - 0s 239us/step - loss: 0.4664 - acc: 0.8165 - val_loss: 0.2655 - val_acc: 0.9178\n",
      "Epoch 38/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3301 - acc: 0.880 - 0s 239us/step - loss: 0.3345 - acc: 0.8807 - val_loss: 0.2670 - val_acc: 0.9041\n",
      "Epoch 39/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2415 - acc: 0.920 - 0s 225us/step - loss: 0.2289 - acc: 0.9266 - val_loss: 0.2583 - val_acc: 0.9041\n",
      "Epoch 40/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3110 - acc: 0.880 - 0s 235us/step - loss: 0.3088 - acc: 0.8716 - val_loss: 0.2869 - val_acc: 0.8904\n",
      "Epoch 41/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3367 - acc: 0.910 - 0s 230us/step - loss: 0.3305 - acc: 0.9083 - val_loss: 0.2633 - val_acc: 0.9178\n",
      "Epoch 42/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3345 - acc: 0.870 - 0s 212us/step - loss: 0.3244 - acc: 0.8807 - val_loss: 0.2524 - val_acc: 0.8904\n",
      "Epoch 43/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4197 - acc: 0.810 - 0s 244us/step - loss: 0.4192 - acc: 0.8165 - val_loss: 0.2494 - val_acc: 0.9178\n",
      "Epoch 44/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1930 - acc: 0.930 - 0s 212us/step - loss: 0.2123 - acc: 0.9174 - val_loss: 0.3965 - val_acc: 0.8767\n",
      "Epoch 45/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4907 - acc: 0.830 - 0s 244us/step - loss: 0.4765 - acc: 0.8349 - val_loss: 0.2747 - val_acc: 0.9178\n",
      "Epoch 46/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3341 - acc: 0.840 - 0s 239us/step - loss: 0.3342 - acc: 0.8349 - val_loss: 0.2966 - val_acc: 0.9041\n",
      "Epoch 47/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2840 - acc: 0.880 - 0s 216us/step - loss: 0.2632 - acc: 0.8899 - val_loss: 0.2575 - val_acc: 0.9041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2227 - acc: 0.910 - 0s 225us/step - loss: 0.2255 - acc: 0.9083 - val_loss: 0.2559 - val_acc: 0.9178\n",
      "Epoch 49/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2305 - acc: 0.890 - 0s 225us/step - loss: 0.2245 - acc: 0.8991 - val_loss: 0.2644 - val_acc: 0.9315\n",
      "Epoch 50/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1505 - acc: 0.950 - 0s 225us/step - loss: 0.1426 - acc: 0.9541 - val_loss: 0.2427 - val_acc: 0.9315\n",
      "Epoch 51/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2173 - acc: 0.930 - 0s 239us/step - loss: 0.2462 - acc: 0.9266 - val_loss: 0.8543 - val_acc: 0.7260\n",
      "Epoch 52/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4688 - acc: 0.820 - 0s 216us/step - loss: 0.4328 - acc: 0.8349 - val_loss: 0.3158 - val_acc: 0.9178\n",
      "Epoch 53/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2164 - acc: 0.930 - 0s 235us/step - loss: 0.2068 - acc: 0.9358 - val_loss: 0.2685 - val_acc: 0.9178\n",
      "Epoch 54/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1451 - acc: 0.950 - 0s 244us/step - loss: 0.1553 - acc: 0.9450 - val_loss: 0.3080 - val_acc: 0.9178\n",
      "Epoch 55/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2215 - acc: 0.910 - 0s 262us/step - loss: 0.2100 - acc: 0.9174 - val_loss: 0.2580 - val_acc: 0.9178\n",
      "Epoch 56/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1141 - acc: 0.970 - 0s 239us/step - loss: 0.1580 - acc: 0.9541 - val_loss: 0.2787 - val_acc: 0.9178\n",
      "Epoch 57/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2800 - acc: 0.930 - 0s 239us/step - loss: 0.2594 - acc: 0.9358 - val_loss: 0.2261 - val_acc: 0.9315\n",
      "Epoch 58/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1565 - acc: 0.950 - 0s 216us/step - loss: 0.1471 - acc: 0.9541 - val_loss: 0.2258 - val_acc: 0.9178\n",
      "Epoch 59/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1422 - acc: 0.980 - 0s 218us/step - loss: 0.1730 - acc: 0.9725 - val_loss: 0.2418 - val_acc: 0.9178\n",
      "Epoch 60/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1412 - acc: 0.980 - 0s 235us/step - loss: 0.1523 - acc: 0.9725 - val_loss: 0.2646 - val_acc: 0.9315\n",
      "Epoch 61/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1373 - acc: 0.950 - 0s 235us/step - loss: 0.1442 - acc: 0.9541 - val_loss: 0.2489 - val_acc: 0.9315\n",
      "Epoch 62/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1569 - acc: 0.950 - 0s 235us/step - loss: 0.1448 - acc: 0.9541 - val_loss: 0.2281 - val_acc: 0.9315\n",
      "Epoch 63/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1712 - acc: 0.940 - 0s 235us/step - loss: 0.1607 - acc: 0.9450 - val_loss: 0.2146 - val_acc: 0.9452\n",
      "Epoch 64/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0985 - acc: 0.960 - 0s 225us/step - loss: 0.1016 - acc: 0.9633 - val_loss: 0.2815 - val_acc: 0.9315\n",
      "Epoch 65/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2732 - acc: 0.920 - 0s 244us/step - loss: 0.2623 - acc: 0.9174 - val_loss: 0.2323 - val_acc: 0.9589\n",
      "Epoch 66/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1690 - acc: 0.940 - 0s 258us/step - loss: 0.1570 - acc: 0.9450 - val_loss: 0.2422 - val_acc: 0.9589\n",
      "Epoch 67/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1325 - acc: 0.960 - 0s 253us/step - loss: 0.1231 - acc: 0.9633 - val_loss: 0.2217 - val_acc: 0.9452\n",
      "Epoch 68/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1052 - acc: 0.970 - 0s 207us/step - loss: 0.1070 - acc: 0.9725 - val_loss: 0.2651 - val_acc: 0.9452\n",
      "Epoch 69/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1631 - acc: 0.920 - 0s 221us/step - loss: 0.1810 - acc: 0.9174 - val_loss: 0.6498 - val_acc: 0.7808\n",
      "Epoch 70/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2584 - acc: 0.920 - 0s 226us/step - loss: 0.2383 - acc: 0.9266 - val_loss: 0.3790 - val_acc: 0.8767\n",
      "Epoch 71/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1482 - acc: 0.930 - 0s 239us/step - loss: 0.1655 - acc: 0.9266 - val_loss: 0.5360 - val_acc: 0.8219\n",
      "Epoch 72/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3491 - acc: 0.910 - 0s 235us/step - loss: 0.3235 - acc: 0.9174 - val_loss: 0.2551 - val_acc: 0.9452\n",
      "Epoch 73/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1086 - acc: 0.970 - 0s 221us/step - loss: 0.1345 - acc: 0.9541 - val_loss: 0.2875 - val_acc: 0.9178\n",
      "Epoch 74/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1654 - acc: 0.950 - 0s 239us/step - loss: 0.1690 - acc: 0.9541 - val_loss: 0.2388 - val_acc: 0.9178\n",
      "Epoch 75/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1335 - acc: 0.960 - 0s 230us/step - loss: 0.1253 - acc: 0.9633 - val_loss: 0.2440 - val_acc: 0.9178\n",
      "Epoch 76/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1223 - acc: 0.970 - 0s 244us/step - loss: 0.1350 - acc: 0.9633 - val_loss: 0.3446 - val_acc: 0.9041\n",
      "Epoch 77/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1369 - acc: 0.980 - 0s 235us/step - loss: 0.1317 - acc: 0.9817 - val_loss: 0.3236 - val_acc: 0.9041\n",
      "Epoch 78/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2122 - acc: 0.940 - 0s 230us/step - loss: 0.2044 - acc: 0.9450 - val_loss: 0.2519 - val_acc: 0.9452\n",
      "Epoch 79/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1269 - acc: 0.960 - 0s 244us/step - loss: 0.1215 - acc: 0.9633 - val_loss: 0.2395 - val_acc: 0.9452\n",
      "Epoch 80/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1143 - acc: 0.970 - 0s 212us/step - loss: 0.1075 - acc: 0.9725 - val_loss: 0.2338 - val_acc: 0.9589\n",
      "Epoch 81/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1505 - acc: 0.940 - 0s 244us/step - loss: 0.1446 - acc: 0.9450 - val_loss: 0.2730 - val_acc: 0.9452\n",
      "Epoch 82/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1003 - acc: 0.980 - 0s 249us/step - loss: 0.0921 - acc: 0.9817 - val_loss: 0.2537 - val_acc: 0.9452\n",
      "Epoch 83/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1268 - acc: 0.960 - 0s 244us/step - loss: 0.1248 - acc: 0.9541 - val_loss: 0.2728 - val_acc: 0.9178\n",
      "Epoch 84/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0635 - acc: 0.970 - 0s 235us/step - loss: 0.1089 - acc: 0.9450 - val_loss: 0.2429 - val_acc: 0.9589\n",
      "Epoch 85/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1331 - acc: 0.960 - 0s 235us/step - loss: 0.1243 - acc: 0.9633 - val_loss: 0.2229 - val_acc: 0.9589\n",
      "Epoch 86/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0759 - acc: 0.980 - 0s 258us/step - loss: 0.0700 - acc: 0.9817 - val_loss: 0.2262 - val_acc: 0.9452\n",
      "Epoch 87/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0558 - acc: 0.990 - 0s 248us/step - loss: 0.0518 - acc: 0.9908 - val_loss: 0.2366 - val_acc: 0.9178\n",
      "Epoch 88/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0731 - acc: 0.980 - 0s 262us/step - loss: 0.0685 - acc: 0.9817 - val_loss: 0.2160 - val_acc: 0.9315\n",
      "Epoch 89/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0529 - acc: 0.980 - 0s 225us/step - loss: 0.0491 - acc: 0.9817 - val_loss: 0.2082 - val_acc: 0.9589\n",
      "Epoch 90/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0564 - acc: 0.980 - 0s 267us/step - loss: 0.0575 - acc: 0.9817 - val_loss: 0.2315 - val_acc: 0.9452\n",
      "Epoch 91/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0389 - acc: 0.990 - 0s 216us/step - loss: 0.0359 - acc: 0.9908 - val_loss: 0.2236 - val_acc: 0.9452\n",
      "Epoch 92/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0738 - acc: 0.980 - 0s 239us/step - loss: 0.0687 - acc: 0.9817 - val_loss: 0.2298 - val_acc: 0.9452\n",
      "Epoch 93/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0513 - acc: 0.990 - 0s 244us/step - loss: 0.0475 - acc: 0.9908 - val_loss: 0.2439 - val_acc: 0.9452\n",
      "Epoch 94/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0373 - acc: 1.000 - 0s 230us/step - loss: 0.0342 - acc: 1.0000 - val_loss: 0.2566 - val_acc: 0.9315\n",
      "Epoch 95/380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - ETA: 0s - loss: 0.0382 - acc: 0.990 - 0s 221us/step - loss: 0.0369 - acc: 0.9908 - val_loss: 0.2602 - val_acc: 0.9315\n",
      "Epoch 96/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0587 - acc: 0.970 - 0s 225us/step - loss: 0.0543 - acc: 0.9725 - val_loss: 0.2324 - val_acc: 0.9589\n",
      "Epoch 97/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0726 - acc: 0.970 - 0s 216us/step - loss: 0.0691 - acc: 0.9725 - val_loss: 0.2107 - val_acc: 0.9452\n",
      "Epoch 98/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0413 - acc: 0.980 - 0s 239us/step - loss: 0.0539 - acc: 0.9725 - val_loss: 0.2487 - val_acc: 0.9452\n",
      "Epoch 99/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0711 - acc: 0.970 - 0s 225us/step - loss: 0.0653 - acc: 0.9725 - val_loss: 0.2264 - val_acc: 0.9452\n",
      "Epoch 100/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0156 - acc: 1.000 - 0s 221us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.2413 - val_acc: 0.9315\n",
      "Epoch 101/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0738 - acc: 0.970 - 0s 258us/step - loss: 0.0744 - acc: 0.9725 - val_loss: 0.2532 - val_acc: 0.9452\n",
      "Epoch 102/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0725 - acc: 0.980 - 0s 235us/step - loss: 0.0667 - acc: 0.9817 - val_loss: 0.2451 - val_acc: 0.9452\n",
      "Epoch 103/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0674 - acc: 0.970 - 0s 221us/step - loss: 0.0695 - acc: 0.9633 - val_loss: 0.2770 - val_acc: 0.9315\n",
      "Epoch 104/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0792 - acc: 0.980 - 0s 225us/step - loss: 0.0795 - acc: 0.9817 - val_loss: 0.2322 - val_acc: 0.9589\n",
      "Epoch 105/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0437 - acc: 0.980 - 0s 235us/step - loss: 0.0419 - acc: 0.9817 - val_loss: 0.2367 - val_acc: 0.9589\n",
      "Epoch 106/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0882 - acc: 0.970 - 0s 235us/step - loss: 0.0849 - acc: 0.9725 - val_loss: 0.2578 - val_acc: 0.9589\n",
      "Epoch 107/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0638 - acc: 0.980 - 0s 230us/step - loss: 0.0603 - acc: 0.9817 - val_loss: 0.2666 - val_acc: 0.9589\n",
      "Epoch 108/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0284 - acc: 1.000 - 0s 258us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.2869 - val_acc: 0.9452\n",
      "Epoch 109/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0154 - acc: 0.990 - 0s 258us/step - loss: 0.0142 - acc: 0.9908 - val_loss: 0.2944 - val_acc: 0.9452\n",
      "Epoch 110/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1214 - acc: 0.980 - 0s 221us/step - loss: 0.1116 - acc: 0.9817 - val_loss: 0.2859 - val_acc: 0.9452\n",
      "Epoch 111/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0298 - acc: 1.000 - 0s 225us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 0.3196 - val_acc: 0.9452\n",
      "Epoch 112/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0355 - acc: 0.990 - 0s 249us/step - loss: 0.0333 - acc: 0.9908 - val_loss: 0.2993 - val_acc: 0.9452\n",
      "Epoch 113/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0548 - acc: 0.980 - 0s 235us/step - loss: 0.0617 - acc: 0.9817 - val_loss: 0.4012 - val_acc: 0.9315\n",
      "Epoch 114/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0276 - acc: 0.990 - 0s 258us/step - loss: 0.0275 - acc: 0.9908 - val_loss: 0.3047 - val_acc: 0.9315\n",
      "Epoch 115/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0413 - acc: 0.990 - 0s 212us/step - loss: 0.0414 - acc: 0.9908 - val_loss: 0.3471 - val_acc: 0.9589\n",
      "Epoch 116/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0579 - acc: 0.980 - 0s 221us/step - loss: 0.0535 - acc: 0.9817 - val_loss: 0.3177 - val_acc: 0.9589\n",
      "Epoch 117/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0334 - acc: 0.980 - 0s 221us/step - loss: 0.0306 - acc: 0.9817 - val_loss: 0.3114 - val_acc: 0.9452\n",
      "Epoch 118/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0516 - acc: 0.960 - 0s 249us/step - loss: 0.0493 - acc: 0.9633 - val_loss: 0.2925 - val_acc: 0.9452\n",
      "Epoch 119/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0336 - acc: 1.000 - 0s 225us/step - loss: 0.0353 - acc: 1.0000 - val_loss: 0.2848 - val_acc: 0.9315\n",
      "Epoch 120/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0976 - acc: 0.960 - 0s 230us/step - loss: 0.1187 - acc: 0.9541 - val_loss: 0.2997 - val_acc: 0.9452\n",
      "Epoch 121/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0924 - acc: 0.980 - 0s 230us/step - loss: 0.0869 - acc: 0.9817 - val_loss: 0.3322 - val_acc: 0.9452\n",
      "Epoch 122/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0160 - acc: 1.000 - 0s 225us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.3354 - val_acc: 0.9452\n",
      "Epoch 123/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0618 - acc: 0.990 - 0s 221us/step - loss: 0.0580 - acc: 0.9908 - val_loss: 0.3062 - val_acc: 0.9452\n",
      "Epoch 124/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0429 - acc: 0.990 - 0s 207us/step - loss: 0.0394 - acc: 0.9908 - val_loss: 0.3224 - val_acc: 0.9452\n",
      "Epoch 125/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0100 - acc: 1.000 - 0s 234us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3175 - val_acc: 0.9452\n",
      "Epoch 126/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0079 - acc: 1.000 - 0s 216us/step - loss: 0.0162 - acc: 0.9908 - val_loss: 0.3640 - val_acc: 0.9452\n",
      "Epoch 127/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0604 - acc: 0.980 - 0s 244us/step - loss: 0.0593 - acc: 0.9817 - val_loss: 0.3328 - val_acc: 0.9315\n",
      "Epoch 128/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0419 - acc: 0.980 - 0s 239us/step - loss: 0.0385 - acc: 0.9817 - val_loss: 0.3055 - val_acc: 0.9452\n",
      "Epoch 129/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0707 - acc: 0.970 - 0s 239us/step - loss: 0.0655 - acc: 0.9725 - val_loss: 0.3100 - val_acc: 0.9452\n",
      "Epoch 130/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0521 - acc: 0.980 - 0s 221us/step - loss: 0.0481 - acc: 0.9817 - val_loss: 0.2658 - val_acc: 0.9452\n",
      "Epoch 131/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0463 - acc: 0.990 - 0s 230us/step - loss: 0.0440 - acc: 0.9908 - val_loss: 0.2176 - val_acc: 0.9452\n",
      "Epoch 132/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0195 - acc: 1.000 - 0s 248us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.2534 - val_acc: 0.9452\n",
      "Epoch 133/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1141 - acc: 0.970 - 0s 244us/step - loss: 0.1058 - acc: 0.9725 - val_loss: 0.2752 - val_acc: 0.9589\n",
      "Epoch 134/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0180 - acc: 0.990 - 0s 212us/step - loss: 0.0165 - acc: 0.9908 - val_loss: 0.2778 - val_acc: 0.9589\n",
      "Epoch 135/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0184 - acc: 1.000 - 0s 244us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.3095 - val_acc: 0.9452\n",
      "Epoch 136/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0307 - acc: 0.990 - 0s 239us/step - loss: 0.0292 - acc: 0.9908 - val_loss: 0.3098 - val_acc: 0.9315\n",
      "Epoch 137/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0304 - acc: 0.990 - 0s 239us/step - loss: 0.0331 - acc: 0.9908 - val_loss: 0.2897 - val_acc: 0.9452\n",
      "Epoch 138/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0133 - acc: 1.000 - 0s 225us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.9452\n",
      "Epoch 139/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0107 - acc: 1.000 - 0s 216us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.2638 - val_acc: 0.9452\n",
      "Epoch 140/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0486 - acc: 0.990 - 0s 235us/step - loss: 0.0970 - acc: 0.9725 - val_loss: 0.3429 - val_acc: 0.9452\n",
      "Epoch 141/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0446 - acc: 0.990 - 0s 202us/step - loss: 0.0420 - acc: 0.9908 - val_loss: 0.3146 - val_acc: 0.9452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0165 - acc: 1.000 - 0s 221us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.2834 - val_acc: 0.9452\n",
      "Epoch 143/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0106 - acc: 1.000 - 0s 225us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.2744 - val_acc: 0.9452\n",
      "Epoch 144/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0233 - acc: 1.000 - 0s 267us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.2648 - val_acc: 0.9589\n",
      "Epoch 145/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0344 - acc: 0.980 - 0s 226us/step - loss: 0.0326 - acc: 0.9817 - val_loss: 0.2875 - val_acc: 0.9452\n",
      "Epoch 146/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0175 - acc: 1.000 - 0s 225us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.3466 - val_acc: 0.9178\n",
      "Epoch 147/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0804 - acc: 0.980 - 0s 272us/step - loss: 0.0743 - acc: 0.9817 - val_loss: 0.2909 - val_acc: 0.9452\n",
      "Epoch 148/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0314 - acc: 0.990 - 0s 230us/step - loss: 0.0364 - acc: 0.9908 - val_loss: 0.3202 - val_acc: 0.9452\n",
      "Epoch 149/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0834 - acc: 0.970 - 0s 217us/step - loss: 0.0777 - acc: 0.9725 - val_loss: 0.3076 - val_acc: 0.9452\n",
      "Epoch 150/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0259 - acc: 0.990 - 0s 249us/step - loss: 0.0393 - acc: 0.9817 - val_loss: 0.3381 - val_acc: 0.9452\n",
      "Epoch 151/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0420 - acc: 0.980 - 0s 226us/step - loss: 0.0388 - acc: 0.9817 - val_loss: 0.3369 - val_acc: 0.9452\n",
      "Epoch 152/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0228 - acc: 0.990 - 0s 216us/step - loss: 0.0209 - acc: 0.9908 - val_loss: 0.3309 - val_acc: 0.9452\n",
      "Epoch 153/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0595 - acc: 0.980 - 0s 235us/step - loss: 0.0604 - acc: 0.9817 - val_loss: 0.3429 - val_acc: 0.9452\n",
      "Epoch 154/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0081 - acc: 1.000 - 0s 235us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3564 - val_acc: 0.9452\n",
      "Epoch 155/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0295 - acc: 0.980 - 0s 216us/step - loss: 0.0275 - acc: 0.9817 - val_loss: 0.3431 - val_acc: 0.9452\n",
      "Epoch 156/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0092 - acc: 1.000 - 0s 248us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3377 - val_acc: 0.9452\n",
      "Epoch 157/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0101 - acc: 0.990 - 0s 253us/step - loss: 0.0093 - acc: 0.9908 - val_loss: 0.3683 - val_acc: 0.9452\n",
      "Epoch 158/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0246 - acc: 0.990 - 0s 244us/step - loss: 0.0226 - acc: 0.9908 - val_loss: 0.3649 - val_acc: 0.9452\n",
      "Epoch 159/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0228 - acc: 1.000 - 0s 230us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.3935 - val_acc: 0.9452\n",
      "Epoch 160/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0308 - acc: 0.980 - 0s 242us/step - loss: 0.0283 - acc: 0.9817 - val_loss: 0.3749 - val_acc: 0.9452\n",
      "Epoch 161/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0284 - acc: 0.990 - 0s 230us/step - loss: 0.0280 - acc: 0.9908 - val_loss: 0.3211 - val_acc: 0.9589\n",
      "Epoch 162/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0601 - acc: 0.960 - 0s 235us/step - loss: 0.0552 - acc: 0.9633 - val_loss: 0.3437 - val_acc: 0.9452\n",
      "Epoch 163/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0099 - acc: 1.000 - 0s 253us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3271 - val_acc: 0.9452\n",
      "Epoch 164/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0112 - acc: 1.000 - 0s 221us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.3425 - val_acc: 0.9452\n",
      "Epoch 165/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0346 - acc: 0.990 - 0s 239us/step - loss: 0.0337 - acc: 0.9908 - val_loss: 0.2996 - val_acc: 0.9452\n",
      "Epoch 166/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0037 - acc: 1.000 - 0s 244us/step - loss: 0.0230 - acc: 0.9908 - val_loss: 0.3932 - val_acc: 0.9178\n",
      "Epoch 167/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0306 - acc: 0.990 - 0s 239us/step - loss: 0.0532 - acc: 0.9817 - val_loss: 0.3215 - val_acc: 0.9589\n",
      "Epoch 168/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0246 - acc: 0.990 - 0s 294us/step - loss: 0.0378 - acc: 0.9817 - val_loss: 0.3804 - val_acc: 0.9315\n",
      "Epoch 169/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0786 - acc: 0.980 - 0s 230us/step - loss: 0.0724 - acc: 0.9817 - val_loss: 0.3274 - val_acc: 0.9452\n",
      "Epoch 170/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0353 - acc: 0.990 - 0s 235us/step - loss: 0.0325 - acc: 0.9908 - val_loss: 0.3051 - val_acc: 0.9589\n",
      "Epoch 171/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0100 - acc: 1.000 - 0s 239us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3161 - val_acc: 0.9452\n",
      "Epoch 172/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0113 - acc: 1.000 - 0s 225us/step - loss: 0.0195 - acc: 0.9908 - val_loss: 0.3015 - val_acc: 0.9452\n",
      "Epoch 173/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0221 - acc: 0.990 - 0s 239us/step - loss: 0.0215 - acc: 0.9908 - val_loss: 0.3143 - val_acc: 0.9452\n",
      "Epoch 174/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0580 - acc: 0.980 - 0s 248us/step - loss: 0.0532 - acc: 0.9817 - val_loss: 0.3508 - val_acc: 0.9452\n",
      "Epoch 175/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0580 - acc: 0.980 - 0s 225us/step - loss: 0.0534 - acc: 0.9817 - val_loss: 0.3585 - val_acc: 0.9452\n",
      "Epoch 176/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0466 - acc: 0.990 - 0s 244us/step - loss: 0.0427 - acc: 0.9908 - val_loss: 0.3213 - val_acc: 0.9452\n",
      "Epoch 177/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0118 - acc: 1.000 - 0s 225us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.2894 - val_acc: 0.9452\n",
      "Epoch 178/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0287 - acc: 0.990 - 0s 248us/step - loss: 0.0266 - acc: 0.9908 - val_loss: 0.3290 - val_acc: 0.9452\n",
      "Epoch 179/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1034 - acc: 0.990 - 0s 216us/step - loss: 0.0949 - acc: 0.9908 - val_loss: 0.3230 - val_acc: 0.9452\n",
      "Epoch 180/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0371 - acc: 0.980 - 0s 235us/step - loss: 0.0341 - acc: 0.9817 - val_loss: 0.3480 - val_acc: 0.9452\n",
      "Epoch 181/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0458 - acc: 0.980 - 0s 225us/step - loss: 0.0420 - acc: 0.9817 - val_loss: 0.3602 - val_acc: 0.9452\n",
      "Epoch 182/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0244 - acc: 1.000 - 0s 225us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.3751 - val_acc: 0.9452\n",
      "Epoch 183/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0105 - acc: 1.000 - 0s 235us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.3659 - val_acc: 0.9452\n",
      "Epoch 184/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0367 - acc: 0.990 - 0s 248us/step - loss: 0.0338 - acc: 0.9908 - val_loss: 0.3268 - val_acc: 0.9452\n",
      "Epoch 185/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0181 - acc: 0.990 - 0s 258us/step - loss: 0.0408 - acc: 0.9817 - val_loss: 0.3836 - val_acc: 0.9452\n",
      "Epoch 186/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0042 - acc: 1.000 - 0s 235us/step - loss: 0.0135 - acc: 0.9908 - val_loss: 0.3450 - val_acc: 0.9452\n",
      "Epoch 187/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0371 - acc: 0.990 - 0s 276us/step - loss: 0.0522 - acc: 0.9817 - val_loss: 0.4324 - val_acc: 0.9452\n",
      "Epoch 188/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1218 - acc: 0.960 - 0s 216us/step - loss: 0.1126 - acc: 0.9633 - val_loss: 0.3535 - val_acc: 0.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0094 - acc: 1.000 - 0s 253us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3496 - val_acc: 0.9315\n",
      "Epoch 190/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0081 - acc: 1.000 - 0s 225us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3358 - val_acc: 0.9315\n",
      "Epoch 191/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0317 - acc: 0.990 - 0s 230us/step - loss: 0.0297 - acc: 0.9908 - val_loss: 0.3402 - val_acc: 0.9452\n",
      "Epoch 192/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0138 - acc: 1.000 - 0s 271us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.3378 - val_acc: 0.9452\n",
      "Epoch 193/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0070 - acc: 1.000 - 0s 230us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.3313 - val_acc: 0.9452\n",
      "Epoch 194/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0061 - acc: 1.000 - 0s 244us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.3541 - val_acc: 0.9452\n",
      "Epoch 195/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0182 - acc: 0.990 - 0s 212us/step - loss: 0.0167 - acc: 0.9908 - val_loss: 0.3513 - val_acc: 0.9452\n",
      "Epoch 196/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0033 - acc: 1.000 - 0s 212us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.3548 - val_acc: 0.9452\n",
      "Epoch 197/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0239 - acc: 0.980 - 0s 239us/step - loss: 0.0220 - acc: 0.9817 - val_loss: 0.3491 - val_acc: 0.9452\n",
      "Epoch 198/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0077 - acc: 1.000 - 0s 235us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3551 - val_acc: 0.9452\n",
      "Epoch 199/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0051 - acc: 1.000 - 0s 230us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.3544 - val_acc: 0.9452\n",
      "Epoch 200/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0115 - acc: 1.000 - 0s 235us/step - loss: 0.0614 - acc: 0.9908 - val_loss: 0.3720 - val_acc: 0.9452\n",
      "Epoch 201/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0275 - acc: 0.990 - 0s 221us/step - loss: 0.0253 - acc: 0.9908 - val_loss: 0.3605 - val_acc: 0.9452\n",
      "Epoch 202/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0140 - acc: 0.990 - 0s 258us/step - loss: 0.0133 - acc: 0.9908 - val_loss: 0.3849 - val_acc: 0.9452\n",
      "Epoch 203/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0130 - acc: 1.000 - 0s 216us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.3838 - val_acc: 0.9452\n",
      "Epoch 204/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0052 - acc: 1.000 - 0s 212us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.3859 - val_acc: 0.9452\n",
      "Epoch 205/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0068 - acc: 1.000 - 0s 225us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.3532 - val_acc: 0.9452\n",
      "Epoch 206/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0045 - acc: 1.000 - 0s 216us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.3537 - val_acc: 0.9452\n",
      "Epoch 207/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0204 - acc: 0.980 - 0s 230us/step - loss: 0.0187 - acc: 0.9817 - val_loss: 0.3587 - val_acc: 0.9452\n",
      "Epoch 208/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.000 - 0s 212us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.3954 - val_acc: 0.9452\n",
      "Epoch 209/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0067 - acc: 1.000 - 0s 258us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3999 - val_acc: 0.9452\n",
      "Epoch 210/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0216 - acc: 0.990 - 0s 230us/step - loss: 0.0202 - acc: 0.9908 - val_loss: 0.4171 - val_acc: 0.9452\n",
      "Epoch 211/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0071 - acc: 1.000 - 0s 225us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4052 - val_acc: 0.9452\n",
      "Epoch 212/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - 0s 239us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.4057 - val_acc: 0.9452\n",
      "Epoch 213/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0214 - acc: 0.980 - 0s 253us/step - loss: 0.0197 - acc: 0.9817 - val_loss: 0.3637 - val_acc: 0.9452\n",
      "Epoch 214/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0079 - acc: 1.000 - 0s 235us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3877 - val_acc: 0.9452\n",
      "Epoch 215/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0128 - acc: 1.000 - 0s 248us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.3827 - val_acc: 0.9452\n",
      "Epoch 216/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - 0s 221us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.3196 - val_acc: 0.9589\n",
      "Epoch 217/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0076 - acc: 1.000 - 0s 212us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3193 - val_acc: 0.9452\n",
      "Epoch 218/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0193 - acc: 1.000 - 0s 244us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.3242 - val_acc: 0.9452\n",
      "Epoch 219/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0069 - acc: 1.000 - 0s 216us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3207 - val_acc: 0.9315\n",
      "Epoch 220/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0128 - acc: 0.990 - 0s 225us/step - loss: 0.0118 - acc: 0.9908 - val_loss: 0.3203 - val_acc: 0.9315\n",
      "Epoch 221/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0043 - acc: 1.000 - 0s 262us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.3220 - val_acc: 0.9315\n",
      "Epoch 222/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0163 - acc: 1.000 - 0s 244us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.3374 - val_acc: 0.9452\n",
      "Epoch 223/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0072 - acc: 1.000 - 0s 239us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3421 - val_acc: 0.9452\n",
      "Epoch 224/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.000 - 0s 248us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.3489 - val_acc: 0.9452\n",
      "Epoch 225/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0025 - acc: 1.000 - 0s 221us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.3461 - val_acc: 0.9452\n",
      "Epoch 226/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0130 - acc: 1.000 - 0s 248us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.3631 - val_acc: 0.9452\n",
      "Epoch 227/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0066 - acc: 1.000 - 0s 202us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.3507 - val_acc: 0.9452\n",
      "Epoch 228/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0094 - acc: 0.990 - 0s 225us/step - loss: 0.0086 - acc: 0.9908 - val_loss: 0.3619 - val_acc: 0.9452\n",
      "Epoch 229/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0284 - acc: 0.990 - 0s 244us/step - loss: 0.0260 - acc: 0.9908 - val_loss: 0.3823 - val_acc: 0.9452\n",
      "Epoch 230/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0487 - acc: 0.980 - 0s 235us/step - loss: 0.0525 - acc: 0.9725 - val_loss: 0.3298 - val_acc: 0.9452\n",
      "Epoch 231/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0095 - acc: 1.000 - 0s 216us/step - loss: 0.0773 - acc: 0.9908 - val_loss: 0.2971 - val_acc: 0.9315\n",
      "Epoch 232/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0835 - acc: 0.980 - 0s 235us/step - loss: 0.0768 - acc: 0.9817 - val_loss: 0.2449 - val_acc: 0.9452\n",
      "Epoch 233/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0281 - acc: 0.990 - 0s 244us/step - loss: 0.0259 - acc: 0.9908 - val_loss: 0.2592 - val_acc: 0.9452\n",
      "Epoch 234/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0032 - acc: 1.000 - 0s 212us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.2959 - val_acc: 0.9452\n",
      "Epoch 235/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0099 - acc: 1.000 - 0s 216us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.2937 - val_acc: 0.9452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0362 - acc: 0.980 - 0s 239us/step - loss: 0.0336 - acc: 0.9817 - val_loss: 0.2922 - val_acc: 0.9452\n",
      "Epoch 237/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0073 - acc: 1.000 - 0s 211us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.2900 - val_acc: 0.9452\n",
      "Epoch 238/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0107 - acc: 0.990 - 0s 244us/step - loss: 0.0100 - acc: 0.9908 - val_loss: 0.2859 - val_acc: 0.9452\n",
      "Epoch 239/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 7.3150e-04 - acc: 1.000 - 0s 248us/step - loss: 7.2799e-04 - acc: 1.0000 - val_loss: 0.2869 - val_acc: 0.9452\n",
      "Epoch 240/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0144 - acc: 0.990 - 0s 221us/step - loss: 0.0132 - acc: 0.9908 - val_loss: 0.2836 - val_acc: 0.9452\n",
      "Epoch 241/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0745 - acc: 0.980 - 0s 225us/step - loss: 0.0683 - acc: 0.9817 - val_loss: 0.3267 - val_acc: 0.9452\n",
      "Epoch 242/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0057 - acc: 1.000 - 0s 227us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.3375 - val_acc: 0.9452\n",
      "Epoch 243/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0103 - acc: 1.000 - 0s 240us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3333 - val_acc: 0.9452\n",
      "Epoch 244/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0059 - acc: 1.000 - 0s 225us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.3206 - val_acc: 0.9452\n",
      "Epoch 245/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.990 - 0s 253us/step - loss: 0.0100 - acc: 0.9908 - val_loss: 0.3369 - val_acc: 0.9452\n",
      "Epoch 246/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 7.3394e-04 - acc: 1.000 - 0s 225us/step - loss: 7.2957e-04 - acc: 1.0000 - val_loss: 0.3363 - val_acc: 0.9452\n",
      "Epoch 247/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0230 - acc: 0.990 - 0s 225us/step - loss: 0.0211 - acc: 0.9908 - val_loss: 0.3700 - val_acc: 0.9452\n",
      "Epoch 248/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0130 - acc: 1.000 - 0s 235us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.3714 - val_acc: 0.9452\n",
      "Epoch 249/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0454 - acc: 0.980 - 0s 225us/step - loss: 0.0416 - acc: 0.9817 - val_loss: 0.3784 - val_acc: 0.9452\n",
      "Epoch 250/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0378 - acc: 0.980 - 0s 207us/step - loss: 0.0348 - acc: 0.9817 - val_loss: 0.3456 - val_acc: 0.9452\n",
      "Epoch 251/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0053 - acc: 1.000 - 0s 225us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.3452 - val_acc: 0.9452\n",
      "Epoch 252/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0059 - acc: 1.000 - 0s 216us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.3692 - val_acc: 0.9452\n",
      "Epoch 253/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.000 - 0s 248us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.4018 - val_acc: 0.9589\n",
      "Epoch 254/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0059 - acc: 1.000 - 0s 239us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.3961 - val_acc: 0.9589\n",
      "Epoch 255/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0274 - acc: 0.990 - 0s 230us/step - loss: 0.0251 - acc: 0.9908 - val_loss: 0.3026 - val_acc: 0.9452\n",
      "Epoch 256/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0111 - acc: 0.990 - 0s 244us/step - loss: 0.0106 - acc: 0.9908 - val_loss: 0.2961 - val_acc: 0.9452\n",
      "Epoch 257/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.000 - 0s 230us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2961 - val_acc: 0.9452\n",
      "Epoch 258/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.000 - 0s 258us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2878 - val_acc: 0.9452\n",
      "Epoch 259/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0078 - acc: 1.000 - 0s 253us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3125 - val_acc: 0.9452\n",
      "Epoch 260/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.000 - 0s 239us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.3137 - val_acc: 0.9452\n",
      "Epoch 261/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0184 - acc: 1.000 - 0s 221us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.2936 - val_acc: 0.9452\n",
      "Epoch 262/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0109 - acc: 1.000 - 0s 225us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.3003 - val_acc: 0.9452\n",
      "Epoch 263/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.000 - 0s 267us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3014 - val_acc: 0.9452\n",
      "Epoch 264/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0106 - acc: 1.000 - 0s 244us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.9452\n",
      "Epoch 265/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0028 - acc: 1.000 - 0s 230us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.3195 - val_acc: 0.9452\n",
      "Epoch 266/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.000 - 0s 198us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.3206 - val_acc: 0.9452\n",
      "Epoch 267/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0115 - acc: 1.000 - 0s 235us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.3725 - val_acc: 0.9452\n",
      "Epoch 268/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0075 - acc: 1.000 - 0s 230us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3596 - val_acc: 0.9452\n",
      "Epoch 269/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0045 - acc: 1.000 - 0s 244us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.3553 - val_acc: 0.9452\n",
      "Epoch 270/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0150 - acc: 0.990 - 0s 253us/step - loss: 0.0175 - acc: 0.9908 - val_loss: 0.3538 - val_acc: 0.9452\n",
      "Epoch 271/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0225 - acc: 0.990 - 0s 248us/step - loss: 0.0210 - acc: 0.9908 - val_loss: 0.3048 - val_acc: 0.9589\n",
      "Epoch 272/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.000 - 0s 258us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.9589\n",
      "Epoch 273/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0099 - acc: 0.990 - 0s 244us/step - loss: 0.0113 - acc: 0.9908 - val_loss: 0.3955 - val_acc: 0.9452\n",
      "Epoch 274/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.000 - 0s 235us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.3495 - val_acc: 0.9315\n",
      "Epoch 275/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0450 - acc: 0.970 - 0s 258us/step - loss: 0.0414 - acc: 0.9725 - val_loss: 0.3314 - val_acc: 0.9452\n",
      "Epoch 276/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0387 - acc: 0.980 - 0s 267us/step - loss: 0.0355 - acc: 0.9817 - val_loss: 0.3607 - val_acc: 0.9452\n",
      "Epoch 277/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0029 - acc: 1.000 - 0s 221us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.3397 - val_acc: 0.9452\n",
      "Epoch 278/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.990 - 0s 249us/step - loss: 0.0099 - acc: 0.9908 - val_loss: 0.3088 - val_acc: 0.9452\n",
      "Epoch 279/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0054 - acc: 1.000 - 0s 262us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.3194 - val_acc: 0.9452\n",
      "Epoch 280/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0039 - acc: 1.000 - 0s 285us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.3438 - val_acc: 0.9452\n",
      "Epoch 281/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0048 - acc: 1.000 - 0s 221us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.3618 - val_acc: 0.9452\n",
      "Epoch 282/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0135 - acc: 1.000 - 0s 234us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.3391 - val_acc: 0.9452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.000 - 0s 212us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.3946 - val_acc: 0.9452\n",
      "Epoch 284/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 5.4298e-04 - acc: 1.000 - 0s 244us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.3737 - val_acc: 0.9452\n",
      "Epoch 285/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0035 - acc: 1.000 - 0s 253us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.3753 - val_acc: 0.9452\n",
      "Epoch 286/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0175 - acc: 0.990 - 0s 239us/step - loss: 0.0269 - acc: 0.9817 - val_loss: 0.3033 - val_acc: 0.9452\n",
      "Epoch 287/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0039 - acc: 1.000 - 0s 239us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.3342 - val_acc: 0.9452\n",
      "Epoch 288/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0059 - acc: 1.000 - 0s 230us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.3718 - val_acc: 0.9452\n",
      "Epoch 289/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.000 - 0s 239us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.3678 - val_acc: 0.9452\n",
      "Epoch 290/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0109 - acc: 1.000 - 0s 225us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3707 - val_acc: 0.9452\n",
      "Epoch 291/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0159 - acc: 0.990 - 0s 202us/step - loss: 0.0146 - acc: 0.9908 - val_loss: 0.3586 - val_acc: 0.9452\n",
      "Epoch 292/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 5.1325e-04 - acc: 1.000 - 0s 248us/step - loss: 4.7399e-04 - acc: 1.0000 - val_loss: 0.3597 - val_acc: 0.9452\n",
      "Epoch 293/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0075 - acc: 1.000 - 0s 202us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3884 - val_acc: 0.9452\n",
      "Epoch 294/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0121 - acc: 0.990 - 0s 254us/step - loss: 0.0112 - acc: 0.9908 - val_loss: 0.3721 - val_acc: 0.9452\n",
      "Epoch 295/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0424 - acc: 0.990 - 0s 226us/step - loss: 0.0389 - acc: 0.9908 - val_loss: 0.3451 - val_acc: 0.9589\n",
      "Epoch 296/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.000 - 0s 199us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.3555 - val_acc: 0.9589\n",
      "Epoch 297/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0095 - acc: 1.000 - 0s 221us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3423 - val_acc: 0.9589\n",
      "Epoch 298/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 6.7534e-04 - acc: 1.000 - 0s 244us/step - loss: 6.2164e-04 - acc: 1.0000 - val_loss: 0.3451 - val_acc: 0.9589\n",
      "Epoch 299/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0056 - acc: 1.000 - 0s 212us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3602 - val_acc: 0.9589\n",
      "Epoch 300/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 3.5812e-04 - acc: 1.000 - 0s 221us/step - loss: 3.8806e-04 - acc: 1.0000 - val_loss: 0.3604 - val_acc: 0.9589\n",
      "Epoch 301/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 3.1461e-04 - acc: 1.000 - 0s 216us/step - loss: 2.9128e-04 - acc: 1.0000 - val_loss: 0.3610 - val_acc: 0.9589\n",
      "Epoch 302/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0343 - acc: 0.990 - 0s 235us/step - loss: 0.0315 - acc: 0.9908 - val_loss: 0.4059 - val_acc: 0.9452\n",
      "Epoch 303/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - 0s 230us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.5084 - val_acc: 0.9315\n",
      "Epoch 304/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0028 - acc: 1.000 - 0s 235us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.4822 - val_acc: 0.9452\n",
      "Epoch 305/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0255 - acc: 0.990 - 0s 253us/step - loss: 0.0321 - acc: 0.9817 - val_loss: 0.3771 - val_acc: 0.9452\n",
      "Epoch 306/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0055 - acc: 1.000 - 0s 244us/step - loss: 0.0130 - acc: 0.9908 - val_loss: 0.5107 - val_acc: 0.9315\n",
      "Epoch 307/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0575 - acc: 0.980 - 0s 216us/step - loss: 0.0946 - acc: 0.9725 - val_loss: 0.6586 - val_acc: 0.8767\n",
      "Epoch 308/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0057 - acc: 1.000 - 0s 216us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5472 - val_acc: 0.8767\n",
      "Epoch 309/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0032 - acc: 1.000 - 0s 253us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.5187 - val_acc: 0.8767\n",
      "Epoch 310/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0451 - acc: 0.990 - 0s 244us/step - loss: 0.0414 - acc: 0.9908 - val_loss: 0.3886 - val_acc: 0.9452\n",
      "Epoch 311/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.000 - 0s 230us/step - loss: 0.0094 - acc: 0.9908 - val_loss: 0.4806 - val_acc: 0.9452\n",
      "Epoch 312/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0486 - acc: 0.980 - 0s 239us/step - loss: 0.0457 - acc: 0.9817 - val_loss: 0.4392 - val_acc: 0.9452\n",
      "Epoch 313/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0227 - acc: 0.990 - 0s 253us/step - loss: 0.0213 - acc: 0.9908 - val_loss: 0.3434 - val_acc: 0.9452\n",
      "Epoch 314/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0050 - acc: 1.000 - 0s 235us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.3302 - val_acc: 0.9452\n",
      "Epoch 315/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.000 - 0s 212us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3262 - val_acc: 0.9452\n",
      "Epoch 316/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0033 - acc: 1.000 - 0s 276us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.3580 - val_acc: 0.9452\n",
      "Epoch 317/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0360 - acc: 0.990 - 0s 225us/step - loss: 0.0330 - acc: 0.9908 - val_loss: 0.3882 - val_acc: 0.9452\n",
      "Epoch 318/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0055 - acc: 1.000 - 0s 221us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.3847 - val_acc: 0.9315\n",
      "Epoch 319/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0159 - acc: 0.990 - 0s 235us/step - loss: 0.0147 - acc: 0.9908 - val_loss: 0.3737 - val_acc: 0.9452\n",
      "Epoch 320/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0334 - acc: 0.990 - 0s 225us/step - loss: 0.0308 - acc: 0.9908 - val_loss: 0.3778 - val_acc: 0.9452\n",
      "Epoch 321/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0098 - acc: 0.990 - 0s 262us/step - loss: 0.0090 - acc: 0.9908 - val_loss: 0.3751 - val_acc: 0.9452\n",
      "Epoch 322/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.000 - 0s 258us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3762 - val_acc: 0.9452\n",
      "Epoch 323/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0077 - acc: 1.000 - 0s 244us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3819 - val_acc: 0.9452\n",
      "Epoch 324/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0124 - acc: 0.990 - 0s 258us/step - loss: 0.0114 - acc: 0.9908 - val_loss: 0.3887 - val_acc: 0.9452\n",
      "Epoch 325/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0061 - acc: 1.000 - 0s 267us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.3800 - val_acc: 0.9452\n",
      "Epoch 326/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0094 - acc: 1.000 - 0s 239us/step - loss: 0.0248 - acc: 0.9908 - val_loss: 0.3888 - val_acc: 0.9315\n",
      "Epoch 327/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0427 - acc: 0.990 - 0s 239us/step - loss: 0.0392 - acc: 0.9908 - val_loss: 0.3870 - val_acc: 0.9452\n",
      "Epoch 328/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0155 - acc: 1.000 - 0s 244us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.4179 - val_acc: 0.9452\n",
      "Epoch 329/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.000 - 0s 244us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4221 - val_acc: 0.9452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0381 - acc: 0.990 - 0s 235us/step - loss: 0.0351 - acc: 0.9908 - val_loss: 0.3884 - val_acc: 0.9452\n",
      "Epoch 331/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0229 - acc: 0.990 - 0s 216us/step - loss: 0.0210 - acc: 0.9908 - val_loss: 0.4025 - val_acc: 0.9452\n",
      "Epoch 332/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0156 - acc: 1.000 - 0s 202us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.4109 - val_acc: 0.9452\n",
      "Epoch 333/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0174 - acc: 0.990 - 0s 221us/step - loss: 0.0160 - acc: 0.9908 - val_loss: 0.3959 - val_acc: 0.9452\n",
      "Epoch 334/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0040 - acc: 1.000 - 0s 202us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.4138 - val_acc: 0.9452\n",
      "Epoch 335/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0032 - acc: 1.000 - 0s 235us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.4159 - val_acc: 0.9452\n",
      "Epoch 336/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0403 - acc: 0.990 - 0s 225us/step - loss: 0.0370 - acc: 0.9908 - val_loss: 0.3901 - val_acc: 0.9452\n",
      "Epoch 337/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0036 - acc: 1.000 - 0s 248us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.3841 - val_acc: 0.9452\n",
      "Epoch 338/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0457 - acc: 0.990 - 0s 230us/step - loss: 0.0433 - acc: 0.9908 - val_loss: 0.3939 - val_acc: 0.9452\n",
      "Epoch 339/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 9.9785e-04 - acc: 1.000 - 0s 244us/step - loss: 9.1603e-04 - acc: 1.0000 - val_loss: 0.3947 - val_acc: 0.9452\n",
      "Epoch 340/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 2.7872e-04 - acc: 1.000 - 0s 202us/step - loss: 2.5586e-04 - acc: 1.0000 - val_loss: 0.3955 - val_acc: 0.9452\n",
      "Epoch 341/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0025 - acc: 1.000 - 0s 212us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.3857 - val_acc: 0.9452\n",
      "Epoch 342/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 3.4157e-04 - acc: 1.000 - 0s 226us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4150 - val_acc: 0.9452\n",
      "Epoch 343/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0051 - acc: 1.000 - 0s 226us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4380 - val_acc: 0.9452\n",
      "Epoch 344/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0038 - acc: 1.000 - 0s 202us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.4421 - val_acc: 0.9452\n",
      "Epoch 345/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0031 - acc: 1.000 - 0s 231us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.4481 - val_acc: 0.9452\n",
      "Epoch 346/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0096 - acc: 1.000 - 0s 235us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4620 - val_acc: 0.9452\n",
      "Epoch 347/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0069 - acc: 1.000 - 0s 243us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4574 - val_acc: 0.9452\n",
      "Epoch 348/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 4.9278e-04 - acc: 1.000 - 0s 259us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.4438 - val_acc: 0.9452\n",
      "Epoch 349/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 7.0673e-04 - acc: 1.000 - 0s 331us/step - loss: 6.4896e-04 - acc: 1.0000 - val_loss: 0.4461 - val_acc: 0.9452\n",
      "Epoch 350/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 4.7793e-04 - acc: 1.000 - 0s 239us/step - loss: 4.9607e-04 - acc: 1.0000 - val_loss: 0.4492 - val_acc: 0.9452\n",
      "Epoch 351/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0130 - acc: 1.000 - 0s 281us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.4473 - val_acc: 0.9452\n",
      "Epoch 352/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.000 - 0s 244us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.4374 - val_acc: 0.9452\n",
      "Epoch 353/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 2.0318e-04 - acc: 1.000 - 0s 239us/step - loss: 1.8866e-04 - acc: 1.0000 - val_loss: 0.4382 - val_acc: 0.9452\n",
      "Epoch 354/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.0452e-04 - acc: 1.000 - 0s 271us/step - loss: 1.5171e-04 - acc: 1.0000 - val_loss: 0.4359 - val_acc: 0.9452\n",
      "Epoch 355/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.8330e-04 - acc: 1.000 - 0s 244us/step - loss: 2.0779e-04 - acc: 1.0000 - val_loss: 0.4403 - val_acc: 0.9452\n",
      "Epoch 356/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0103 - acc: 1.000 - 0s 248us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.4407 - val_acc: 0.9452\n",
      "Epoch 357/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 5.2650e-04 - acc: 1.000 - 0s 235us/step - loss: 9.7465e-04 - acc: 1.0000 - val_loss: 0.4405 - val_acc: 0.9452\n",
      "Epoch 358/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 7.6994e-04 - acc: 1.000 - 0s 267us/step - loss: 9.6498e-04 - acc: 1.0000 - val_loss: 0.4502 - val_acc: 0.9452\n",
      "Epoch 359/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0417 - acc: 0.990 - 0s 276us/step - loss: 0.0383 - acc: 0.9908 - val_loss: 0.4743 - val_acc: 0.9452\n",
      "Epoch 360/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0028 - acc: 1.000 - 0s 235us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.4668 - val_acc: 0.9452\n",
      "Epoch 361/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0115 - acc: 1.000 - 0s 212us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.4988 - val_acc: 0.9452\n",
      "Epoch 362/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.000 - 0s 258us/step - loss: 9.2098e-04 - acc: 1.0000 - val_loss: 0.5019 - val_acc: 0.9452\n",
      "Epoch 363/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0309 - acc: 0.980 - 0s 230us/step - loss: 0.0283 - acc: 0.9817 - val_loss: 0.4453 - val_acc: 0.9452\n",
      "Epoch 364/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0209 - acc: 0.990 - 0s 230us/step - loss: 0.0192 - acc: 0.9908 - val_loss: 0.4888 - val_acc: 0.9452\n",
      "Epoch 365/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.000 - 0s 235us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4917 - val_acc: 0.9452\n",
      "Epoch 366/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - 0s 230us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5003 - val_acc: 0.9452\n",
      "Epoch 367/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0042 - acc: 1.000 - 0s 212us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.4846 - val_acc: 0.9452\n",
      "Epoch 368/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 8.8836e-04 - acc: 1.000 - 0s 239us/step - loss: 8.1534e-04 - acc: 1.0000 - val_loss: 0.4784 - val_acc: 0.9452\n",
      "Epoch 369/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0231 - acc: 0.990 - 0s 202us/step - loss: 0.0213 - acc: 0.9908 - val_loss: 0.4598 - val_acc: 0.9452\n",
      "Epoch 370/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0029 - acc: 1.000 - 0s 258us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.4705 - val_acc: 0.9452\n",
      "Epoch 371/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0043 - acc: 1.000 - 0s 221us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.4591 - val_acc: 0.9452\n",
      "Epoch 372/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 6.5036e-04 - acc: 1.000 - 0s 253us/step - loss: 6.0739e-04 - acc: 1.0000 - val_loss: 0.4601 - val_acc: 0.9452\n",
      "Epoch 373/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0144 - acc: 0.990 - 0s 253us/step - loss: 0.0132 - acc: 0.9908 - val_loss: 0.4588 - val_acc: 0.9452\n",
      "Epoch 374/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0125 - acc: 0.990 - 0s 244us/step - loss: 0.0117 - acc: 0.9908 - val_loss: 0.4602 - val_acc: 0.9452\n",
      "Epoch 375/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 7.7564e-04 - acc: 1.000 - 0s 253us/step - loss: 7.2135e-04 - acc: 1.0000 - val_loss: 0.4589 - val_acc: 0.9452\n",
      "Epoch 376/380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - ETA: 0s - loss: 0.0025 - acc: 1.000 - 0s 235us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.4430 - val_acc: 0.9452\n",
      "Epoch 377/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0054 - acc: 1.000 - 0s 216us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4424 - val_acc: 0.9452\n",
      "Epoch 378/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0129 - acc: 0.990 - 0s 235us/step - loss: 0.0118 - acc: 0.9908 - val_loss: 0.4508 - val_acc: 0.9452\n",
      "Epoch 379/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0469 - acc: 0.990 - 0s 202us/step - loss: 0.0431 - acc: 0.9908 - val_loss: 0.4757 - val_acc: 0.9452\n",
      "Epoch 380/380\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.0041 - acc: 1.000 - 0s 239us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.4600 - val_acc: 0.9452\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))\n",
    "\n",
    "# export model\n",
    "model.save('saved_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bass-drum bass-drum 0.008505582809448242 secs\n",
      "bass-drum bass-drum 0.009519338607788086 secs\n",
      "bass-drum bass-drum 0.010027170181274414 secs\n",
      "bass-drum bass-drum 0.009024381637573242 secs\n",
      "bass-drum bass-drum 0.00852203369140625 secs\n",
      "bass-drum bass-drum 0.010025262832641602 secs\n",
      "bass-drum bass-drum 0.00852203369140625 secs\n",
      "bass-drum bass-drum 0.009529352188110352 secs\n",
      "bass-drum bass-drum 0.010026931762695312 secs\n",
      "bass-drum bass-drum 0.010025262832641602 secs\n",
      "bass-drum bass-drum 0.009523868560791016 secs\n",
      "bass-drum bass-drum 0.00952601432800293 secs\n",
      "bass-drum bass-drum 0.009523630142211914 secs\n",
      "bass-drum bass-drum 0.008530139923095703 secs\n",
      "bass-drum bass-drum 0.009524106979370117 secs\n",
      "bass-drum bass-drum 0.010024309158325195 secs\n",
      "bass-drum bass-drum 0.008521556854248047 secs\n",
      "bass-drum bass-drum 0.009022951126098633 secs\n",
      "bass-drum bass-drum 0.009516716003417969 secs\n",
      "bass-drum bass-drum 0.008522272109985352 secs\n",
      "cowbell cowbell 0.00952291488647461 secs\n",
      "cowbell cowbell 0.010026693344116211 secs\n",
      "cowbell cowbell 0.010027170181274414 secs\n",
      "cowbell cowbell 0.010523796081542969 secs\n",
      "cowbell cowbell 0.010024547576904297 secs\n",
      "cowbell cowbell 0.009517908096313477 secs\n",
      "cowbell cowbell 0.009519815444946289 secs\n",
      "cowbell cowbell 0.009510993957519531 secs\n",
      "cowbell cowbell 0.009522676467895508 secs\n",
      "cowbell cowbell 0.00952601432800293 secs\n",
      "cowbell cowbell 0.009525775909423828 secs\n",
      "cowbell cowbell 0.010027170181274414 secs\n",
      "cowbell cowbell 0.010026931762695312 secs\n",
      "cowbell cowbell 0.009519338607788086 secs\n",
      "cowbell cowbell 0.009023666381835938 secs\n",
      "cowbell cowbell 0.009025812149047852 secs\n",
      "cowbell cowbell 0.009023666381835938 secs\n",
      "cowbell cowbell 0.009029626846313477 secs\n",
      "cowbell cowbell 0.010035276412963867 secs\n",
      "cowbell cowbell 0.010024070739746094 secs\n",
      "cowbell cowbell 0.01052546501159668 secs\n",
      "cowbell toms 0.009022951126098633 secs\n",
      "cymbal cymbal 0.010524511337280273 secs\n",
      "cymbal cymbal 0.009525537490844727 secs\n",
      "cymbal cymbal 0.010526657104492188 secs\n",
      "cymbal cymbal 0.009524345397949219 secs\n",
      "cymbal cymbal 0.009026050567626953 secs\n",
      "cymbal cymbal 0.00802159309387207 secs\n",
      "cymbal cymbal 0.008019685745239258 secs\n",
      "cymbal cymbal 0.008521556854248047 secs\n",
      "cymbal cymbal 0.008523225784301758 secs\n",
      "cymbal cymbal 0.008523941040039062 secs\n",
      "cymbal cymbal 0.008022546768188477 secs\n",
      "cymbal cymbal 0.008523225784301758 secs\n",
      "cymbal cymbal 0.008530378341674805 secs\n",
      "cymbal cymbal 0.009528875350952148 secs\n",
      "cymbal cymbal 0.010020017623901367 secs\n",
      "cymbal cymbal 0.009525775909423828 secs\n",
      "cymbal cymbal 0.009023427963256836 secs\n",
      "cymbal cymbal 0.009525060653686523 secs\n",
      "cymbal cymbal 0.010026216506958008 secs\n",
      "cymbal cymbal 0.00902247428894043 secs\n",
      "cymbal cymbal 0.00952458381652832 secs\n",
      "cymbal cymbal 0.010024547576904297 secs\n",
      "handclap handclap 0.008521556854248047 secs\n",
      "handclap handclap 0.008020401000976562 secs\n",
      "handclap handclap 0.00902104377746582 secs\n",
      "handclap handclap 0.008521556854248047 secs\n",
      "handclap handclap 0.00902104377746582 secs\n",
      "handclap handclap 0.008509159088134766 secs\n",
      "handclap handclap 0.009022712707519531 secs\n",
      "handclap handclap 0.008521556854248047 secs\n",
      "handclap handclap 0.009524345397949219 secs\n",
      "handclap handclap 0.008520126342773438 secs\n",
      "handclap handclap 0.009023427963256836 secs\n",
      "handclap rimshot 0.009018421173095703 secs\n",
      "handclap handclap 0.008524894714355469 secs\n",
      "handclap handclap 0.008521795272827148 secs\n",
      "handclap handclap 0.008520841598510742 secs\n",
      "handclap handclap 0.007518291473388672 secs\n",
      "handclap handclap 0.007517337799072266 secs\n",
      "handclap handclap 0.008522748947143555 secs\n",
      "handclap handclap 0.008523225784301758 secs\n",
      "handclap handclap 0.00801992416381836 secs\n",
      "handclap handclap 0.008519887924194336 secs\n",
      "handclap handclap 0.00801992416381836 secs\n",
      "handclap handclap 0.008020401000976562 secs\n",
      "handclap handclap 0.0075185298919677734 secs\n",
      "handclap handclap 0.008520364761352539 secs\n",
      "hi-hat hi-hat 0.00751948356628418 secs\n",
      "hi-hat hi-hat 0.00902414321899414 secs\n",
      "hi-hat hi-hat 0.008522510528564453 secs\n",
      "hi-hat hi-hat 0.008522748947143555 secs\n",
      "hi-hat hi-hat 0.009036540985107422 secs\n",
      "hi-hat hi-hat 0.009021759033203125 secs\n",
      "hi-hat hi-hat 0.008523225784301758 secs\n",
      "hi-hat hi-hat 0.008520364761352539 secs\n",
      "hi-hat hi-hat 0.008522510528564453 secs\n",
      "hi-hat hi-hat 0.008023500442504883 secs\n",
      "hi-hat hi-hat 0.009022951126098633 secs\n",
      "hi-hat hi-hat 0.009023666381835938 secs\n",
      "hi-hat hi-hat 0.008521795272827148 secs\n",
      "hi-hat hi-hat 0.0075190067291259766 secs\n",
      "hi-hat hi-hat 0.009523391723632812 secs\n",
      "hi-hat hi-hat 0.007531881332397461 secs\n",
      "hi-hat hi-hat 0.009524345397949219 secs\n",
      "hi-hat hi-hat 0.009522676467895508 secs\n",
      "hi-hat hi-hat 0.008021116256713867 secs\n",
      "hi-hat rimshot 0.008020639419555664 secs\n",
      "hi-hat hi-hat 0.008021354675292969 secs\n",
      "hi-hat hi-hat 0.008522272109985352 secs\n",
      "rimshot rimshot 0.007519960403442383 secs\n",
      "rimshot rimshot 0.008522272109985352 secs\n",
      "rimshot rimshot 0.00852203369140625 secs\n",
      "rimshot rimshot 0.008521080017089844 secs\n",
      "rimshot rimshot 0.008522748947143555 secs\n",
      "rimshot rimshot 0.008008241653442383 secs\n",
      "rimshot rimshot 0.009022951126098633 secs\n",
      "rimshot rimshot 0.00852203369140625 secs\n",
      "rimshot rimshot 0.008522748947143555 secs\n",
      "rimshot rimshot 0.00802159309387207 secs\n",
      "rimshot rimshot 0.008522748947143555 secs\n",
      "rimshot rimshot 0.008521795272827148 secs\n",
      "rimshot rimshot 0.008522510528564453 secs\n",
      "rimshot rimshot 0.009525537490844727 secs\n",
      "rimshot snare 0.009023427963256836 secs\n",
      "rimshot rimshot 0.009023427963256836 secs\n",
      "rimshot rimshot 0.008021116256713867 secs\n",
      "rimshot rimshot 0.008522510528564453 secs\n",
      "rimshot rimshot 0.009023904800415039 secs\n",
      "rimshot rimshot 0.008522272109985352 secs\n",
      "rimshot rimshot 0.00902247428894043 secs\n",
      "rimshot rimshot 0.009023427963256836 secs\n",
      "rimshot rimshot 0.008021116256713867 secs\n",
      "rimshot rimshot 0.008021116256713867 secs\n",
      "snare snare 0.009021997451782227 secs\n",
      "snare snare 0.008522748947143555 secs\n",
      "snare snare 0.008021116256713867 secs\n",
      "snare snare 0.00852203369140625 secs\n",
      "snare snare 0.00852346420288086 secs\n",
      "snare snare 0.008021116256713867 secs\n",
      "snare snare 0.008013248443603516 secs\n",
      "snare snare 0.008523941040039062 secs\n",
      "snare snare 0.008020877838134766 secs\n",
      "snare snare 0.009524345397949219 secs\n",
      "snare snare 0.009022712707519531 secs\n",
      "snare snare 0.00852203369140625 secs\n",
      "snare snare 0.009539365768432617 secs\n",
      "snare snare 0.00901937484741211 secs\n",
      "snare snare 0.00903177261352539 secs\n",
      "snare snare 0.008522272109985352 secs\n",
      "snare snare 0.009022951126098633 secs\n",
      "snare snare 0.009013175964355469 secs\n",
      "snare snare 0.008022069931030273 secs\n",
      "snare snare 0.008533477783203125 secs\n",
      "snare snare 0.009027242660522461 secs\n",
      "snare snare 0.008021354675292969 secs\n",
      "snare snare 0.00902414321899414 secs\n",
      "toms toms 0.00902414321899414 secs\n",
      "toms toms 0.008020401000976562 secs\n",
      "toms toms 0.008021354675292969 secs\n",
      "toms toms 0.008510112762451172 secs\n",
      "toms toms 0.008521795272827148 secs\n",
      "toms toms 0.008522987365722656 secs\n",
      "toms toms 0.008018970489501953 secs\n",
      "toms toms 0.008022069931030273 secs\n",
      "toms toms 0.007018089294433594 secs\n",
      "toms toms 0.009021759033203125 secs\n",
      "toms toms 0.008521318435668945 secs\n",
      "toms toms 0.008536338806152344 secs\n",
      "toms toms 0.009017705917358398 secs\n",
      "toms toms 0.008521080017089844 secs\n",
      "toms toms 0.009021997451782227 secs\n",
      "toms toms 0.00952291488647461 secs\n",
      "toms toms 0.008015871047973633 secs\n",
      "toms toms 0.008522510528564453 secs\n",
      "toms toms 0.009038209915161133 secs\n",
      "toms toms 0.008522272109985352 secs\n",
      "toms toms 0.009033679962158203 secs\n",
      "toms toms 0.008522748947143555 secs\n",
      "toms toms 0.00852203369140625 secs\n",
      "toms toms 0.008521318435668945 secs\n"
     ]
    }
   ],
   "source": [
    "test('damon-trainingdata-clean', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "f = open('model.json', 'w')\n",
    "f.write(json_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": [{\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d_4\", \"trainable\": true, \"batch_input_shape\": [null, 20, 11, 1], \"dtype\": \"float32\", \"filters\": 32, \"kernel_size\": [2, 2], \"strides\": [1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d_5\", \"trainable\": true, \"filters\": 48, \"kernel_size\": [2, 2], \"strides\": [1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d_6\", \"trainable\": true, \"filters\": 120, \"kernel_size\": [2, 2], \"strides\": [1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"max_pooling2d_2\", \"trainable\": true, \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_4\", \"trainable\": true, \"rate\": 0.25, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten_2\", \"trainable\": true}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_4\", \"trainable\": true, \"units\": 128, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_5\", \"trainable\": true, \"rate\": 0.25, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_5\", \"trainable\": true, \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_6\", \"trainable\": true, \"rate\": 0.4, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_6\", \"trainable\": true, \"units\": 8, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"keras_version\": \"2.1.3\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
